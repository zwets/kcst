#!/bin/sh
#
#  kcst - k-mer counting sequence typer
#  Copyright (C) 2018  Marco van Zwetselaar <io@zwets.it>
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#  Home: https://github.com/zwets/kcst

# Make sure sort and awk run predictably and fast
export LC_ALL="C"

# Constants
PROGNAME="$(basename "$0")"
TAB="$(printf '\t')"

# Defaults
KHC_EXE="$(realpath "$(dirname "$0")/khc")"
DB_DIR="$(realpath "$(dirname "$(realpath "$0")")/../data")"
PCT_COVER=90
SAMPLE_NTH=1

# Function outputs $* on stderr
err_msg() {
    echo "${PROGNAME}: $*" >&2
}

# Function exits this script with $* on stderr
err_exit() {
    err_msg $*
    exit 1
}

# Function emits $* on stderr if VERBOSE is set
dbg_msg() {
    [ -z "$VERBOSE" ] || echo "${PROGNAME}: $*" >&2
}

# Function to perform the KHC queries; args $@ are added to its end.
# Output is, for each query, a sequence of lines scheme:gene:allele len hit cov,
# followed by a newline.
khc_query() {
    $KHC_EXE -s -t -c $PCT_COVER "$MLST_DB" "$@"
    echo "DONE"
}

# Transforms into tab-separated 'scheme, gene, allele[*], cov', sorted on decreasing cov
# then keeps only the highest cov line(s) for each gene
top_hits() {
    while true; do
        $GAWK_EXE -bO 'BEGIN { OFS="\t" }
            /^##/    { print }
            /^$/     { exit }
            /^DONE$/ { print "~~~DONE~~~"; exit }
            /^[^#]/  { match($1, "^(.*):(.*):([0-9]+)$", A); print A[1], A[2], A[3] ($4<100.0?"*":""), $4 }' |
        $SORT_EXE -t "$TAB" -k 1,2 -k 4,4nr |
        $GAWK_EXE -bO 'BEGIN { OFS=FS="\t" }
            /^~~~DONE~~~$/ { exit 1 }
            $1 == P1 && $2 == P2 && $4 == P4 { print }
            $1 != P1 || $2 != P2 { P1 = $1; P2 = $2; P4 = $4; print }' || break
        echo
    done
}

# Trickiest bit: take sorted list of scheme, gene, allele, cov, and turn into profile(s),
# then for each profile lookup ST and add it to table that is output
make_profiles() {
    $GAWK_EXE -bO -v CFG_FILE="$DB_DIR/mlst.cfg" -v TSV_FILE="$DB_DIR/mlst.tsv" \
        --source '
        BEGIN {
            FS = OFS = "\t"
            while (getline <CFG_FILE) { 
                SCHEME_NAME[$1] = $2
                SCHEME_LOCI[$1][1]=0; delete SCHEME_LOCI[$1][1]
                N_SCHEME_LOCI[$1] = split($3, SCHEME_LOCI[$1], ",")
            }
            while (getline <TSV_FILE) { 
                KEY = $1
                for (I in SCHEME_LOCI[$1]) KEY = KEY "\t" $(I+2)
                ST_TABLE[KEY "$"] = $2
            }
        }
        /^##/   { TITLE = $0 }
        /^$/    { print_output(TITLE); delete SCHEMES; delete ALLELES; }
        /^[^#]+/ {
            SCHEMES[$1] = $1
            ALLELES[$1][$2][$3] = $3
        }
        END {
            print_output("Species/MLST_scheme")
        }
        function print_output(HDR,   S,P,PS) {
            for (S in SCHEMES) print_scheme(HDR,S)
        }
        function print_scheme(HDR,S,   PS,L,P) {
            if (profiles_from(S,1,PS)) {
                printf "#" HDR OFS "ST"; for (L in SCHEME_LOCI[S]) printf OFS SCHEME_LOCI[S][L]; printf ORS
                for (P in PS) print SCHEME_NAME[S], lookup_st(S, P), P
            }
        }
        function profiles_from(S,I,PS,   AS,LH,RH,RHS) {
            if (! isarray(ALLELES[S][SCHEME_LOCI[S][I]])) 
                return 0
            if (I == N_SCHEME_LOCI[S]) 
                for (LH in ALLELES[S][SCHEME_LOCI[S][I]]) PS[LH] = LH
            else if (profiles_from(S,I+1,RHS))
                for (LH in ALLELES[S][SCHEME_LOCI[S][I]]) for (RH in RHS) PS[LH OFS RH] = LH OFS RH
            return isarray(PS) && length(PS)
        }
        function lookup_st(S,P) 
        {
            ST = ST_TABLE[S "\t" gensub("\\*", "", "g", P) "$"]
            return (ST ? "ST" ST : "NF") gensub("[^*]","","g",P)
        }'
}


# Function to show usage information and exit
usage_exit() {
    echo "
Usage: $PROGNAME [OPTIONS] FILE ...

  Determine species and MLST for the contigs, reads, or plain DNA in each
  FILE in turn.  FILE must be FASTA, FASTQ, or DNA, and may be gzipped.

  OPTIONS
   -c, --cov=COV    Minimum percentage allele coverage (default $PCT_COVER)
   -s, --sample=N   For fastq files: sample every N-th read (default 1)
   -d, --dbdir=DIR  Path to the kcst MLST database directory (see below)
                    (default $DB_DIR)
   -x, --khc=KHC    Path to the khc binary, if not in bin directory or PATH
   -v, --verbose    Report progress on stderr

  The program outputs the species and sequence type (if found) corresponding
  to the combination of top scoring alleles for each gene.  Matches below 100%
  identity are marked with an asterisk (*).  Matches below COV are ignored.

  When the input is FASTQ, the lookup process can be speeded up by sampling a
  subset of the reads (--sample), at the cost of lower sensitivity.

  $PROGNAME uses the khc binary to do the k-mer counting.  khc must have been
  compiled and must be either on the PATH, or in the same directory with kcst,
  or specified with option --khc.
  
  The database directory DIR must have been previously set up according to the
  instructions in README.md.  More information: https://github.com/zwets/kcst.
" >&2
    exit ${1:-1}
}

# Parse options

unset VERBOSE
while [ $# -ne 0 -a "$(expr "$1" : '\(.\)..*')" = "-" ]; do
    case $1 in
    --db*=*)      DB_DIR="${1##--db*=}" ;;
    -d|--db*)     shift || usage_exit; DB_DIR="$1" ;;
    --cov*=*)     PCT_COVER="${1##--cover*=}" ;;
    -c|--cov*)    shift || usage_exit; PCT_COVER="$1" ;;
    --sample=*)   SAMPLE_NTH="${1##--sample=}" ;;
    -s|--sample)  shift || usage_exit; SAMPLE_NTH="$1" ;;
    --khc=*)      KHC_EXE="${1##--khc=}" ;;
    -x|--khc)     shift || usage_exit; KHC_EXE="$1" ;;
    -v|--verbose) VERBOSE=1 ;;
    -h|--help)    usage_exit 0 ;;
    *)            usage_exit ;;
    esac
    shift || usage_exit
done

# Check dependencies

# Functions checks that command '$1' is available, and sets $1_EXE to its path
check_deps() {
    while [ $# -gt 0 ]; do
        local VAR="$(echo "$1_EXE" | tr 'a-z' 'A-Z')"   # VAR = name of environment variable specifying path to $1
        local EXE="$(eval "echo \$$VAR")"               # EXE = value of VAR = user-specified path to $1
        local EXE="${EXE:-"$(command -v "$1")"}"        # If it was not set by user, then try the standard lookup
        [ -x "$EXE" ] && dbg_msg "$VAR = $EXE" || 
            err_exit "missing requirement: '$1'; either put it on PATH or export $VAR=/path/to/$1."
        eval "$VAR=$EXE"
        shift
    done
}

check_deps 'file' 'gawk' 'sort'

# Check arguments

[ $SAMPLE_NTH = 1 ] || err_exit "awww, sorry, read sampling not yet implemented!"

# Check for KHC

KHC_EXE="${KHC_EXE:-"$(command -v khc)"}"
[ -x "$KHC_EXE" ] || err_exit "khc binary not found; compile it and use option -x or PATH"

# Check for database

[ -d "$DB_DIR" ] || err_exit "no such directory (use option -d): $DB_DIR"

MLST_DB="$DB_DIR/mlst.db"
MLST_CFG="$DB_DIR/mlst.cfg"
MLST_TSV="$DB_DIR/mlst.tsv"

[ -f "$MLST_DB" ] || err_exit "database file missing (use option -d): $MLST_DB"
[ -f "$MLST_CFG" ] || err_exit "database config file missing: $MLST_CFG"
[ -f "$MLST_TSV" ] || err_exit "database profile table missing: $MLST_TSV"
[ $# -gt 0 ] || usage_exit

# Do the work

khc_query "$@" |
top_hits |
make_profiles

exit 0

# vim: sts=4:sw=4:et:si:ai
